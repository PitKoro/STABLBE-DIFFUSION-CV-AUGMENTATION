{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3de71460-6d5c-4562-a699-c3d27a398f1e",
   "metadata": {},
   "source": [
    "# Экпериментальный метод аугментации данных при помощи модели Stable Diffusion\n",
    "\n",
    "\n",
    "Предварительно в label-studio разметили области в которых будем генерировать дефекты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b43b908-7d1a-400d-83db-cf31e2a9fc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import autocast\n",
    "from diffusers import StableDiffusionInpaintPipelineLegacy\n",
    "from diffusers.pipelines.stable_diffusion import safety_checker\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "from pycocotools.coco import COCO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "LABELID2TEXT = {0:'crack', 1:'fistula', 2:'rupture'}\n",
    "PROMT_TEMAPLTE = '<OBJ> on a metal pipe'\n",
    "\n",
    "\n",
    "def sc(self, clip_input, images) :\n",
    "    return images, [False for i in images]\n",
    "# edit StableDiffusionSafetyChecker class so that, when called, it just returns the images and an array of True values\n",
    "safety_checker.StableDiffusionSafetyChecker.forward = sc\n",
    "\n",
    "\n",
    "def get_512x512_bbox_from_orig_bbox(defect_bbox, orig_img_w, orig_img_h):\n",
    "    bbox_x, bbox_y, bbox_w, bbox_h =  defect_bbox\n",
    "    if int(bbox_w) < 512:\n",
    "        bbox_x -= (512 - bbox_w) / 2\n",
    "    if int(bbox_h) < 512:\n",
    "        bbox_y -= (512 - bbox_h) / 2\n",
    "\n",
    "    #Проверяем увеличенный ббокс на выход за границы изображения\n",
    "    x1, y1 = (bbox_x, bbox_y)\n",
    "    x2, y2 = (bbox_x + 512, bbox_y + 512)\n",
    "\n",
    "    new_offset_x = 0\n",
    "    new_offset_y = 0\n",
    "    if x2 > orig_img_w:\n",
    "        new_offset_x = orig_img_w - x2\n",
    "    if y2 > orig_img_h:\n",
    "        new_offset_y = orig_img_h - y2\n",
    "    if x1 < 0:\n",
    "        new_offset_x = -x1\n",
    "    if y1 < 0:\n",
    "        new_offset_y = -y1\n",
    "\n",
    "    x1 += new_offset_x\n",
    "    y1 += new_offset_y\n",
    "    \n",
    "    return [x1, y1, 512, 512]\n",
    "\n",
    "\n",
    "def get_mask_of_defect(orig_img, defect_bbox):\n",
    "    img_rgba = orig_img.convert('RGBA')\n",
    "    draw = ImageDraw.Draw(img_rgba)\n",
    "    w,h = img_rgba.size\n",
    "    leftUpPoint = (defect_bbox[0], defect_bbox[1])\n",
    "    rightDownPoint = (defect_bbox[0] + defect_bbox[2], defect_bbox[1] + defect_bbox[3])\n",
    "    twoPointList = [leftUpPoint, rightDownPoint]\n",
    "    draw.rectangle(twoPointList, fill=(255, 255, 255, 0))\n",
    "\n",
    "    img_np = np.array(img_rgba)\n",
    "    mask = img_np[:, :, 3] == 0\n",
    "    mask = Image.fromarray(mask)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_img_and_mask_for_sd_inference(orig_img, defect_bbox):\n",
    "    mask_of_defect = get_mask_of_defect(orig_img, defect_bbox)\n",
    "    w, h  = orig_img.size\n",
    "    bbox_512x512 = get_512x512_bbox_from_orig_bbox(defect_bbox, w, h)\n",
    "    \n",
    "    cropped_img512x512 = orig_img.crop([\n",
    "        bbox_512x512[0],\n",
    "        bbox_512x512[1],\n",
    "        bbox_512x512[0] + 512,\n",
    "        bbox_512x512[1] + 512\n",
    "    ])\n",
    "    \n",
    "    cropped_mask512x512 = mask_of_defect.crop([\n",
    "        bbox_512x512[0],\n",
    "        bbox_512x512[1],\n",
    "        bbox_512x512[0] + 512,\n",
    "        bbox_512x512[1] + 512\n",
    "    ])\n",
    "    \n",
    "    return cropped_img512x512, cropped_mask512x512, bbox_512x512\n",
    "\n",
    "\n",
    "def generate_prompt_by_cat_id(category_id):\n",
    "    return PROMT_TEMAPLTE.replace('<OBJ>', LABELID2TEXT[category_id])\n",
    "\n",
    "\n",
    "def pasting_img_to_img_by_bbox(orig_img, generated_img, bbox):\n",
    "    pass\n",
    "\n",
    "\n",
    "def image_grid(imgs, rows, cols):\n",
    "    assert len(imgs) == rows*cols\n",
    "\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    "    grid_w, grid_h = grid.size\n",
    "    StableDiffusionInpaintPipelineLegacy\n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9276a7e-397a-452f-8c66-b98865901ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_file = '/app/img/origs/result.json'\n",
    "img_path = '/app/img/origs'\n",
    "path_to_augmentated_img = '/app/dataset/augmentated'\n",
    "path_to_stable_diffusion_weights = \"/app/checkpoints/sd-weights-one-prompt-15000iters\"\n",
    "hf_token = \"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\"\n",
    "\n",
    "number_of_genereation_for_one_defects = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73b15a1b-05fd-448d-b296-d81357c86a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco = COCO(ann_file)\n",
    "coco_dict = coco.__dict__['dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee6d4247-0063-415e-af02-3a1b53be1f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 0, 'name': 'crack'},\n",
       " {'id': 1, 'name': 'fistula'},\n",
       " {'id': 2, 'name': 'rupture'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats = coco.loadCats(coco.getCatIds())\n",
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cdec7c3-1cdc-462c-8ad7-1810cc2e83fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_ann = dict()\n",
    "aug_ann['categories'] = cats\n",
    "aug_ann['info'] = coco_dict['info']\n",
    "aug_ann['images'] = []\n",
    "aug_ann['annotations'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74f24ac2-daf2-4ff1-adee-bd092bfa2764",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "pipe = StableDiffusionInpaintPipelineLegacy.from_pretrained(\n",
    "    path_to_stable_diffusion_weights, torch_dtype=torch.float16, use_auth_token=hf_token\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5a6f9d0-8aab-49ca-ba6e-342c2aa6a939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccdc407627f143d9a8c8c35a5326a310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d4ebb4de0134a96825f5a2d81c8126e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a047f0aa2a54b5f88592793f8bae8fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac46e5b137d64af2819ba86f869484c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29d72b9daa69486d85dad336b5b509a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4bf867d6b9f41798d8ffcb859dda153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c04b9b1140ce4fb796e1fd65bf0347e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33782983812744dca3d6fbadea395d9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7508ad5d8dae4810bdc9b6827dbc8a43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de442b64fe85437ab96fb23c17bf09f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d5da4864bb4c0c87bdb518fbc17d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e25d941ccff94b11a0d883dfe0591722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "391c17510bac407baadeff41b1b205df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.4 s, sys: 387 ms, total: 48.7 s\n",
      "Wall time: 43.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ann_id = 0\n",
    "id_for_augmentated_img = 0\n",
    "\n",
    "for img_from_ann in coco_dict['images']:\n",
    "    img_orig = Image.open(f'{img_path}/{img_from_ann[\"file_name\"]}')\n",
    "    anns_ids = coco.getAnnIds(imgIds=img_from_ann[\"id\"])\n",
    "    anns = coco.loadAnns(anns_ids)\n",
    "    for ann in anns:\n",
    "        bbox = ann['bbox'].copy()\n",
    "        category_id = ann['category_id']\n",
    "        # Создаем изображение и маску для инференса стебля\n",
    "        img_for_sd_inference, mask_for_sd_inference, bbox_512x512 = get_img_and_mask_for_sd_inference(img_orig, bbox)\n",
    "        # Генерируем промпт для инференса стебля\n",
    "        prompt = generate_prompt_by_cat_id(category_id)\n",
    "        # Генерируем дефект на трубе\n",
    "        generated_images_with_defects = [pipe(prompt=prompt, init_image=img_for_sd_inference, mask_image=mask_for_sd_inference).images[0] for i in range(number_of_genereation_for_one_defects)]\n",
    "        generation_id = 0\n",
    "        # Накладываем сгенерированное изображение на исходное\n",
    "        for generated_image_with_defect in generated_images_with_defects:\n",
    "            bbox_512x512_int = [round(el) for el in bbox_512x512]\n",
    "            img_orig_copy = img_orig.copy()\n",
    "            img_orig_copy.paste(generated_image_with_defect, (bbox_512x512_int[0], bbox_512x512_int[1]))\n",
    "            orig_img_with_defect = img_orig_copy.copy()\n",
    "            size_of_orig_img_with_defect = orig_img_with_defect.size\n",
    "            new_img_name = f'aug_img_id{id_for_augmentated_img}_cat{category_id}_iter{generation_id}.jpg'\n",
    "            orig_img_with_defect.save(f'{path_to_augmentated_img}/{new_img_name}')\n",
    "            generation_id += 1\n",
    "\n",
    "\n",
    "            aug_ann['images'].append(\n",
    "                {\n",
    "                    \"width\": size_of_orig_img_with_defect[0],\n",
    "                    \"height\": size_of_orig_img_with_defect[1],\n",
    "                    \"id\": id_for_augmentated_img,\n",
    "                    \"file_name\": new_img_name\n",
    "                }\n",
    "            )\n",
    "\n",
    "            aug_ann['annotations'].append(\n",
    "                {\n",
    "                    \"id\": ann_id,\n",
    "                    \"image_id\": id_for_augmentated_img,\n",
    "                    \"category_id\": int(category_id),\n",
    "                    \"segmentation\": [],\n",
    "                    \"bbox\": ann['bbox'],\n",
    "                    \"ignore\": 0,\n",
    "                    \"iscrowd\": 0,\n",
    "                    \"area\": ann['area']\n",
    "                }\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "            ann_id += 1\n",
    "            id_for_augmentated_img += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe512aa-5a6d-4fc9-aac6-f0b7c3a01c28",
   "metadata": {},
   "source": [
    "Сохраняем аннотации в формате coco:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "539f4898-7424-40bf-add5-ee6e3fe57a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(f\"{path_to_augmentated_img}/aug_result.json\", 'w') as f:\n",
    "    json.dump(aug_ann, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0bb12b-f5d0-4215-a159-b4ea65e4b4dd",
   "metadata": {},
   "source": [
    "### COCO to label-studio format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72bd9dd9-3c07-4d72-a8ae-fed73c17508a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'label-studio-converter'...\n",
      "remote: Enumerating objects: 1645, done.\u001b[K\n",
      "remote: Counting objects: 100% (657/657), done.\u001b[K\n",
      "remote: Compressing objects: 100% (232/232), done.\u001b[K\n",
      "remote: Total 1645 (delta 538), reused 434 (delta 425), pack-reused 988\u001b[K\n",
      "Receiving objects: 100% (1645/1645), 2.67 MiB | 1.80 MiB/s, done.\n",
      "Resolving deltas: 100% (964/964), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/heartexlabs/label-studio-converter.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b084712e-dd38-4103-9c70-5ed3aade762f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///app/notebooks/label-studio-converter\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.24.0 in /opt/conda/lib/python3.7/site-packages (from label-studio-converter==0.0.50.dev0) (1.3.5)\n",
      "Requirement already satisfied: requests<3,>=2.22.0 in /opt/conda/lib/python3.7/site-packages (from label-studio-converter==0.0.50.dev0) (2.28.2)\n",
      "Collecting Pillow==9.3.0\n",
      "  Downloading Pillow-9.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nltk==3.6.7\n",
      "  Downloading nltk-3.6.7-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting label-studio-tools==0.0.1\n",
      "  Downloading label_studio_tools-0.0.1-py3-none-any.whl (10 kB)\n",
      "Collecting lxml>=4.2.5\n",
      "  Downloading lxml-4.9.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting appdirs>=1.4.3\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting click\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from nltk==3.6.7->label-studio-converter==0.0.50.dev0) (4.64.1)\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.7/site-packages (from nltk==3.6.7->label-studio-converter==0.0.50.dev0) (2022.10.31)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.24.0->label-studio-converter==0.0.50.dev0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.24.0->label-studio-converter==0.0.50.dev0) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.24.0->label-studio-converter==0.0.50.dev0) (1.21.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.22.0->label-studio-converter==0.0.50.dev0) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.22.0->label-studio-converter==0.0.50.dev0) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.22.0->label-studio-converter==0.0.50.dev0) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.22.0->label-studio-converter==0.0.50.dev0) (2.0.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->label-studio-converter==0.0.50.dev0) (1.16.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click->nltk==3.6.7->label-studio-converter==0.0.50.dev0) (6.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->nltk==3.6.7->label-studio-converter==0.0.50.dev0) (4.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->nltk==3.6.7->label-studio-converter==0.0.50.dev0) (3.15.0)\n",
      "Installing collected packages: appdirs, Pillow, lxml, joblib, label-studio-tools, click, nltk, label-studio-converter\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: Pillow 9.0.1\n",
      "    Uninstalling Pillow-9.0.1:\n",
      "      Successfully uninstalled Pillow-9.0.1\n",
      "  Running setup.py develop for label-studio-converter\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -e ./label-studio-converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b71f7630-512b-4f73-b38b-0ef51bd2adeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: label-studio-converter: not found\n"
     ]
    }
   ],
   "source": [
    "!label-studio-converter import coco -i /app/img/test_stable_aug_ann_with_three_imgs.json -o img/stable_aug_for_label_studio.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81faac1d-0d33-46ea-9e2b-4c63be83b749",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
